name: Joongang News Crawler

on:
  schedule:
    # 매일 한국 시간 기준 오전 6시 (UTC 시간 기준으로 -9시간 계산)
    - cron: '0 21 * * *'
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'
        architecture: 'x64'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 tqdm nbconvert jupyter

    - name: Run crawler
      run: jupyter nbconvert --to notebook --execute JoongAng_crawler.ipynb

    - name: Commit and push if there are changes
      run: |
        git config --global user.email "abs3011@konkuk.ac.kr"
        git config --global user.name "Kyuwon"
        git add result/joongang_news.csv
        git commit -m "Update Joongang News Data csv $(date +'%Y-%m-%d')"
        git push https://${{ secrets.KYUWONTOKEN }}@github.com/konkuk-distributed-system/news-recommendation.git main
