name: YeonHap News Crawler

on:
  schedule:
    # 매일 한국 시간 기준 오전 6시 (UTC 시간 기준으로 -9시간 계산)
    - cron: '0 21 * * *'
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'
        architecture: 'x64'
    - name: List files
      run: |
         pwd
         ls -l
         ls -l result/

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 tqdm nbconvert jupyter

    - name: Run crawler
      run: jupyter nbconvert --to notebook --execute yeonHap_crawler.ipynb

    - name: Display CSV content
      run: cat result/yeonhap_news.csv

    - name: Commit and push if there are changes
      run: |
        git config --global user.email "abs3011@konkuk.ac.kr"
        git config --global user.name "Kyuwon"
        git add result/yeonhap_news.csv
        git diff --cached --exit-code || (git commit -m "Update YeonHap News Data csv $(date +'%Y-%m-%d')" && git push https://${{ secrets.KYUWONTOKEN }}@github.com/konkuk-distributed-system/news-recommendation.git main)
