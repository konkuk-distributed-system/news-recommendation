{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38abb4d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing titles:   0%|                                                                      | 0/1234 [00:00<?, ?it/s]\u001b[A\n",
      "Processing titles:   0%|                                                              | 1/1234 [00:00<02:25,  8.45it/s]\u001b[A\n",
      "Processing titles:   0%|                                                              | 2/1234 [00:00<02:48,  7.31it/s]\u001b[A\n",
      "Processing titles:   0%|▏                                                             | 3/1234 [00:00<02:30,  8.16it/s]\u001b[A\n",
      "Processing titles:   0%|▎                                                             | 5/1234 [00:00<02:15,  9.06it/s]\u001b[A\n",
      "Processing titles:   1%|▊                                                        | 18/1234 [41:30<46:44:40, 138.39s/it]\u001b[A\n",
      "\n",
      "Processing titles:   1%|▍                                                             | 8/1234 [00:07<24:54,  1.22s/it]\u001b[A\n",
      "Processing titles:   1%|▍                                                            | 10/1234 [00:07<15:17,  1.33it/s]\u001b[A\n",
      "Processing titles:   1%|▌                                                            | 12/1234 [00:07<10:08,  2.01it/s]\u001b[A\n",
      "Processing titles:   1%|▋                                                            | 14/1234 [00:07<07:11,  2.83it/s]\u001b[A\n",
      "Processing titles:   1%|▊                                                            | 16/1234 [00:13<24:17,  1.20s/it]\u001b[A\n",
      "Processing titles:   1%|▉                                                            | 18/1234 [00:13<17:13,  1.18it/s]\u001b[A\n",
      "Processing titles:   2%|▉                                                            | 19/1234 [00:14<14:45,  1.37it/s]\u001b[A\n",
      "Processing titles:   2%|▉                                                            | 20/1234 [00:20<37:10,  1.84s/it]\u001b[A\n",
      "Processing titles:   2%|█▏                                                           | 23/1234 [00:20<20:03,  1.01it/s]\u001b[A\n",
      "Processing titles:   2%|█▏                                                           | 24/1234 [00:20<17:03,  1.18it/s]\u001b[A\n",
      "Processing titles:   2%|█▏                                                           | 25/1234 [00:26<38:04,  1.89s/it]\u001b[A\n",
      "Processing titles:   2%|█▎                                                           | 26/1234 [00:26<30:17,  1.50s/it]\u001b[A\n",
      "Processing titles:   2%|█▎                                                           | 27/1234 [00:26<23:32,  1.17s/it]\u001b[A\n",
      "Processing titles:   2%|█▍                                                           | 29/1234 [00:26<14:30,  1.38it/s]\u001b[A\n",
      "Processing titles:   2%|█▍                                                           | 30/1234 [00:32<35:30,  1.77s/it]\u001b[A\n",
      "Processing titles:   3%|█▌                                                           | 31/1234 [00:32<27:38,  1.38s/it]\u001b[A\n",
      "Processing titles:   3%|█▌                                                           | 32/1234 [00:32<21:12,  1.06s/it]\u001b[A\n",
      "Processing titles:   3%|█▋                                                           | 34/1234 [00:32<13:01,  1.54it/s]\u001b[A\n",
      "Processing titles:   3%|█▋                                                           | 35/1234 [00:38<36:19,  1.82s/it]\u001b[A\n",
      "Processing titles:   3%|█▊                                                           | 37/1234 [00:38<23:18,  1.17s/it]\u001b[A\n",
      "Processing titles:   3%|█▉                                                           | 38/1234 [00:38<18:41,  1.07it/s]\u001b[A\n",
      "Processing titles:   3%|█▉                                                           | 39/1234 [00:44<41:49,  2.10s/it]\u001b[A\n",
      "Processing titles:   3%|██                                                           | 42/1234 [00:44<20:56,  1.05s/it]\u001b[A\n",
      "Processing titles:   4%|██▏                                                          | 44/1234 [00:45<14:48,  1.34it/s]\u001b[A\n",
      "Processing titles:   4%|██▏                                                          | 45/1234 [00:45<12:46,  1.55it/s]\u001b[A\n",
      "Processing titles:   4%|██▎                                                          | 46/1234 [00:50<33:27,  1.69s/it]\u001b[A\n",
      "Processing titles:   4%|██▎                                                          | 47/1234 [00:50<26:20,  1.33s/it]\u001b[A\n",
      "Processing titles:   4%|██▍                                                          | 49/1234 [00:51<16:34,  1.19it/s]\u001b[A\n",
      "Processing titles:   4%|██▍                                                          | 50/1234 [00:56<37:55,  1.92s/it]\u001b[A\n",
      "Processing titles:   4%|██▌                                                          | 52/1234 [00:57<23:51,  1.21s/it]\u001b[A\n",
      "Processing titles:   4%|██▌                                                          | 53/1234 [00:57<19:35,  1.00it/s]\u001b[A\n",
      "Processing titles:   4%|██▋                                                          | 55/1234 [00:57<12:27,  1.58it/s]\u001b[A\n",
      "Processing titles:   5%|██▊                                                          | 57/1234 [01:03<27:54,  1.42s/it]\u001b[A\n",
      "Processing titles:   5%|██▉                                                          | 59/1234 [01:03<18:57,  1.03it/s]\u001b[A\n",
      "Processing titles:   5%|███                                                          | 61/1234 [01:03<13:09,  1.49it/s]\u001b[A\n",
      "Processing titles:   5%|███▏                                                         | 64/1234 [01:09<24:04,  1.23s/it]\u001b[A\n",
      "Processing titles:   5%|███▏                                                         | 65/1234 [01:09<20:28,  1.05s/it]\u001b[A\n",
      "Processing titles:   5%|███▎                                                         | 66/1234 [01:09<17:30,  1.11it/s]\u001b[A\n",
      "Processing titles:   5%|███▎                                                         | 67/1234 [01:09<14:13,  1.37it/s]\u001b[A\n",
      "Processing titles:   6%|███▎                                                         | 68/1234 [01:15<37:38,  1.94s/it]\u001b[A\n",
      "Processing titles:   6%|███▍                                                         | 69/1234 [01:15<28:46,  1.48s/it]\u001b[A\n",
      "Processing titles:   6%|███▍                                                         | 70/1234 [01:16<21:59,  1.13s/it]\u001b[A\n",
      "Processing titles:   6%|███▌                                                         | 71/1234 [01:16<16:52,  1.15it/s]\u001b[A\n",
      "Processing titles:   6%|███▌                                                         | 72/1234 [01:22<43:40,  2.26s/it]\u001b[A\n",
      "Processing titles:   6%|███▌                                                         | 73/1234 [01:22<32:35,  1.68s/it]\u001b[A\n",
      "Processing titles:   6%|███▋                                                         | 74/1234 [01:22<24:02,  1.24s/it]\u001b[A\n",
      "Processing titles:   6%|███▋                                                         | 75/1234 [01:22<17:58,  1.07it/s]\u001b[A\n",
      "Processing titles:   6%|███▊                                                         | 76/1234 [01:28<44:36,  2.31s/it]\u001b[A\n",
      "Processing titles:   6%|███▊                                                         | 77/1234 [01:28<32:57,  1.71s/it]\u001b[A\n",
      "Processing titles:   6%|███▊                                                         | 78/1234 [01:28<24:09,  1.25s/it]\u001b[A\n",
      "Processing titles:   6%|███▉                                                         | 79/1234 [01:34<49:33,  2.57s/it]\u001b[A\n",
      "Processing titles:   6%|███▉                                                         | 80/1234 [01:34<35:57,  1.87s/it]\u001b[A\n",
      "Processing titles:   7%|████                                                         | 81/1234 [01:34<26:08,  1.36s/it]\u001b[A\n",
      "Processing titles:   7%|████                                                         | 82/1234 [01:40<50:26,  2.63s/it]\u001b[A\n",
      "Processing titles:   7%|███▉                                                       | 83/1234 [01:51<1:39:34,  5.19s/it]\u001b[A\n",
      "Processing titles:   7%|████▏                                                        | 85/1234 [01:51<54:15,  2.83s/it]\u001b[A\n",
      "Processing titles:   7%|████▎                                                        | 86/1234 [01:52<42:12,  2.21s/it]\u001b[A\n",
      "Processing titles:   7%|████▎                                                        | 87/1234 [01:57<57:04,  2.99s/it]\u001b[A\n",
      "Processing titles:   7%|████▍                                                        | 90/1234 [01:57<27:38,  1.45s/it]\u001b[A\n",
      "Processing titles:   7%|████▌                                                        | 92/1234 [01:57<18:50,  1.01it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing titles:   8%|████▋                                                        | 95/1234 [02:03<25:22,  1.34s/it]\u001b[A\n",
      "Processing titles:   8%|████▊                                                        | 98/1234 [02:03<16:12,  1.17it/s]\u001b[A\n",
      "Processing titles:   8%|████▊                                                       | 100/1234 [02:03<12:23,  1.52it/s]\u001b[A\n",
      "Processing titles:   8%|████▉                                                       | 102/1234 [02:08<22:29,  1.19s/it]\u001b[A\n",
      "Processing titles:   8%|█████                                                       | 104/1234 [02:08<16:45,  1.12it/s]\u001b[A\n",
      "Processing titles:   9%|█████                                                       | 105/1234 [02:13<29:22,  1.56s/it]\u001b[A\n",
      "Processing titles:   9%|█████▎                                                      | 108/1234 [02:13<17:22,  1.08it/s]\u001b[A\n",
      "Processing titles:   9%|█████▎                                                      | 110/1234 [02:14<13:06,  1.43it/s]\u001b[A\n",
      "Processing titles:   9%|█████▍                                                      | 112/1234 [02:19<22:46,  1.22s/it]\u001b[A\n",
      "Processing titles:   9%|█████▍                                                      | 113/1234 [02:19<19:12,  1.03s/it]\u001b[A\n",
      "Processing titles:   9%|█████▌                                                      | 114/1234 [02:19<16:19,  1.14it/s]\u001b[A\n",
      "Processing titles:   9%|█████▌                                                      | 115/1234 [02:19<13:18,  1.40it/s]\u001b[A\n",
      "Processing titles:   9%|█████▋                                                      | 117/1234 [02:24<26:03,  1.40s/it]\u001b[A\n",
      "Processing titles:  10%|█████▊                                                      | 119/1234 [02:24<17:11,  1.08it/s]\u001b[A\n",
      "Processing titles:  10%|█████▊                                                      | 120/1234 [02:24<14:28,  1.28it/s]\u001b[A\n",
      "Processing titles:  10%|█████▉                                                      | 121/1234 [02:25<11:46,  1.57it/s]\u001b[A\n",
      "Processing titles:  10%|█████▉                                                      | 122/1234 [02:29<30:16,  1.63s/it]\u001b[A\n",
      "Processing titles:  10%|██████                                                      | 124/1234 [02:30<18:43,  1.01s/it]\u001b[A\n",
      "Processing titles:  10%|██████                                                      | 125/1234 [02:30<15:00,  1.23it/s]\u001b[A\n",
      "Processing titles:  10%|██████▏                                                     | 126/1234 [02:30<12:09,  1.52it/s]\u001b[A\n",
      "Processing titles:  10%|██████▎                                                     | 129/1234 [02:35<20:26,  1.11s/it]\u001b[A\n",
      "Processing titles:  11%|██████▎                                                     | 130/1234 [02:35<17:01,  1.08it/s]\u001b[A\n",
      "Processing titles:  11%|██████▍                                                     | 132/1234 [02:35<11:22,  1.62it/s]\u001b[A\n",
      "Processing titles:  11%|██████▍                                                     | 133/1234 [02:35<09:36,  1.91it/s]\u001b[A\n",
      "Processing titles:  11%|██████▌                                                     | 135/1234 [02:40<21:36,  1.18s/it]\u001b[A\n",
      "Processing titles:  11%|██████▌                                                     | 136/1234 [02:40<17:31,  1.04it/s]\u001b[A\n",
      "Processing titles:  11%|██████▋                                                     | 138/1234 [02:40<11:45,  1.55it/s]\u001b[A\n",
      "Processing titles:  11%|██████▊                                                     | 139/1234 [02:45<27:39,  1.52s/it]\u001b[A\n",
      "Processing titles:  11%|██████▊                                                     | 141/1234 [02:45<18:02,  1.01it/s]\u001b[A\n",
      "Processing titles:  12%|██████▉                                                     | 142/1234 [02:45<14:39,  1.24it/s]\u001b[A\n",
      "Processing titles:  12%|██████▉                                                     | 143/1234 [02:51<34:28,  1.90s/it]\u001b[A\n",
      "Processing titles:  12%|███████                                                     | 146/1234 [02:51<17:58,  1.01it/s]\u001b[A\n",
      "Processing titles:  12%|███████▏                                                    | 147/1234 [02:51<15:34,  1.16it/s]\u001b[A\n",
      "Processing titles:  12%|███████▎                                                    | 150/1234 [02:57<23:48,  1.32s/it]\u001b[A\n",
      "Processing titles:  12%|███████▍                                                    | 152/1234 [02:57<16:56,  1.06it/s]\u001b[A\n",
      "Processing titles:  12%|███████▍                                                    | 153/1234 [02:57<14:28,  1.24it/s]\u001b[A\n",
      "Processing titles:  12%|███████▍                                                    | 154/1234 [03:03<31:43,  1.76s/it]\u001b[A\n",
      "Processing titles:  13%|███████▌                                                    | 155/1234 [03:03<25:19,  1.41s/it]\u001b[A\n",
      "Processing titles:  13%|███████▌                                                    | 156/1234 [03:03<20:05,  1.12s/it]\u001b[A\n",
      "Processing titles:  13%|███████▋                                                    | 157/1234 [03:03<15:31,  1.16it/s]\u001b[A\n",
      "Processing titles:  13%|███████▋                                                    | 158/1234 [03:09<38:17,  2.14s/it]\u001b[A\n",
      "Processing titles:  13%|███████▉                                                    | 162/1234 [03:09<15:23,  1.16it/s]\u001b[A\n",
      "Processing titles:  13%|███████▉                                                    | 164/1234 [03:09<11:09,  1.60it/s]\u001b[A\n",
      "Processing titles:  13%|████████                                                    | 166/1234 [03:09<08:07,  2.19it/s]\u001b[A\n",
      "Processing titles:  14%|████████▏                                                   | 168/1234 [03:15<20:33,  1.16s/it]\u001b[A\n",
      "Processing titles:  14%|████████▎                                                   | 170/1234 [03:15<15:14,  1.16it/s]\u001b[A\n",
      "Processing titles:  14%|████████▎                                                   | 171/1234 [03:15<12:56,  1.37it/s]\u001b[A\n",
      "Processing titles:  14%|████████▍                                                   | 173/1234 [03:21<25:00,  1.41s/it]\u001b[A\n",
      "Processing titles:  14%|████████▍                                                   | 174/1234 [03:21<20:32,  1.16s/it]\u001b[A\n",
      "Processing titles:  14%|████████▌                                                   | 176/1234 [03:27<31:55,  1.81s/it]\u001b[A\n",
      "Processing titles:  14%|████████▋                                                   | 178/1234 [03:27<21:34,  1.23s/it]\u001b[A\n",
      "Processing titles:  15%|████████▋                                                   | 179/1234 [03:27<17:52,  1.02s/it]\u001b[A\n",
      "Processing titles:  15%|████████▊                                                   | 181/1234 [03:27<12:09,  1.44it/s]\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28392/882020194.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;31m# 전처리된 제목 리스트 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0mprocessed_titles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Processing titles\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;31m# 생성된 제목 리스트로 Word2Vec 모델 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28392/882020194.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;31m# 전처리된 제목 리스트 생성\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0mprocessed_titles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mpreprocess_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtitle\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Processing titles\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;31m# 생성된 제목 리스트로 Word2Vec 모델 학습\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_28392/882020194.py\u001b[0m in \u001b[0;36mpreprocess_text\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'[^\\w\\s]'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# 토큰화 및 불용어 제거 후 조사 명사 동사만 남기기\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mokt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mpos\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Josa'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Noun'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Verb'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mtokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstop_words\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\konlpy\\tag\\_okt.py\u001b[0m in \u001b[0;36mpos\u001b[1;34m(self, phrase, norm, stem, join)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0mvalidate_phrase_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphrase\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         tokens = self.jki.tokenize(\n\u001b[0m\u001b[0;32m     72\u001b[0m                     \u001b[0mphrase\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m                     \u001b[0mjpype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBoolean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from konlpy.tag import Okt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec\n",
    "import time\n",
    "\n",
    "# 텍스트 전처리 함수 정의\n",
    "def preprocess_text(text):\n",
    "    # 소문자 변환 형식상 \n",
    "    text = text.lower()\n",
    "    # 특수 문자 제거\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # 토큰화 및 불용어 제거 후 조사 명사 동사만 남기기\n",
    "    tokens = okt.pos(text)\n",
    "    tokens = [word for word, pos in tokens if pos in ['Josa', 'Noun', 'Verb']]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "## 모델을 받아 변환을 하고 문서 용어 행렬을 반환하는 함수\n",
    "def display_transform_dtm(cvect, corpus):\n",
    "    print(\"Fitting and transforming the corpus...\")\n",
    "    dtm = cvect.fit_transform(tqdm(corpus, desc=\"Transforming corpus\"))\n",
    "    vocab = cvect.get_feature_names()\n",
    "    print(\"Creating the DataFrame...\")\n",
    "    df_dtm = pd.DataFrame(dtm.toarray(), columns=vocab) ## 굳이 Dafatrame으로 보지않아도됨 시간 오래걸림 \n",
    "    return df_dtm.style.background_gradient()\n",
    "\n",
    "\n",
    "# 한국어 불용어 리스트 정의\n",
    "stop_words = set([\n",
    "    '의', '가', '이', '은', '들', '는', '좀', '잘', '걍', '과', '도', '를', \n",
    "    '으로', '자', '에', '와', '한', '하다', '에서', '에게', '이다', '위해'\n",
    "])\n",
    "\n",
    "#예시 데이터 \n",
    "corpus = [\"코로나 거리두기와 코로나 상생지원금 문의입니다.\",\n",
    "          \"지하철 운행시간과 지하철 요금 문의입니다.\",\n",
    "          \"지하철 승강장 문의입니다.\",\n",
    "          \"코로나 선별진료소 문의입니다.\",\n",
    "          \"버스 운행시간 문의입니다.\", \n",
    "          \"버스 터미널 위치 안내입니다.\",\n",
    "          \"코로나 거리두기 안내입니다.\",\n",
    "          \"택시 승강장 문의입니다.\"\n",
    "         ]\n",
    "\n",
    "# 한국어 형태소 분석기 Okt 객체 생성\n",
    "okt = Okt()\n",
    "\n",
    "#측정시작 \n",
    "start_time = time.time()\n",
    "\n",
    "# CSV 파일 읽어서 저장 기사 Content \n",
    "file_path = 'result'\n",
    "file_name = 'joongang_news(test).csv'\n",
    "csv_file_path = os.path.join(file_path, file_name)\n",
    "\n",
    "titles = []\n",
    "with open(csv_file_path, newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        titles.append(row['Content'])\n",
    "        \n",
    "# 전처리된 제목 리스트 생성\n",
    "processed_titles = [preprocess_text(title) for title in tqdm(titles, desc=\"Processing titles\")]\n",
    "\n",
    "# 생성된 제목 리스트로 Word2Vec 모델 학습\n",
    "word2vec_model = Word2Vec(processed_titles, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# 전처리된 배열 출력 (일부만 출력)\n",
    "#print(processed_titles[:10])\n",
    "\n",
    "## cvect 단어 빈도수 기반 벡터 토크나이저 \n",
    "cvect = CountVectorizer() \n",
    "## TF-IDF를 적용한 벡터 토크나이져 \n",
    "tfidfvect = TfidfVectorizer()\n",
    "\n",
    "# 파마메터 조정 확인용 \n",
    "# ngram_range=(2, 3) : 토큰을 묶는 방식 파라메터 default 1:1\n",
    "# min_df=2 : 해당 값보다 낮은 빈도수의 토큰(용어)은 무시한다. \n",
    "# max_df=0.7 : 너무 자주 등장하는 토큰은 무시한다. \n",
    "# stop_words=[] : 불용어 리스트, 해당 리스트에 있는 단어는 무시 \n",
    "# analyzer='char' : char, char_wb 있음 \n",
    "\n",
    "# 화면에 보여주기용 \n",
    "#display(display_transform_dtm(tfidfvect, processed_titles))\n",
    "#display_transform_dtm(cvect, titles)\n",
    "\n",
    "\n",
    "# TF-IDF 벡터화 및 희소 행렬 생성\n",
    "dtm = tfidfvect.fit_transform(processed_titles)\n",
    "\n",
    "# 특징 이름(단어) 리스트\n",
    "feature_names = tfidfvect.get_feature_names()\n",
    "\n",
    "# 희소 행렬을 밀집 행렬로 변환\n",
    "dense = dtm.todense()\n",
    "\n",
    "# 밀집 행렬을 numpy 배열로 변환\n",
    "denselist = dense.tolist()\n",
    "\n",
    "# TF-IDF 결과 출력 (예제: 첫 10개 문서)\n",
    "for i in range(10):\n",
    "    print(f\"문서 {i+1}의 TF-IDF 결과:\")\n",
    "    doc = denselist[i]\n",
    "    phrase_scores = [pair for pair in zip(range(0, len(doc)), doc) if pair[1] > 0]\n",
    "    sorted_phrase_scores = sorted(phrase_scores, key=lambda t: t[1] * -1)\n",
    "    for phrase, score in sorted_phrase_scores:\n",
    "        print(f\"  {feature_names[phrase]}: {score}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "# 입력 단어에 대한 유사 단어 찾기 및 TF-IDF 값 계산\n",
    "def find_similar_words(input_word):\n",
    "    similar_words = word2vec_model.wv.most_similar(input_word, topn=10)\n",
    "    similar_words_tf_idf = {}\n",
    "    for word, similarity in similar_words:\n",
    "        if word in feature_names:\n",
    "            index = feature_names.tolist().index(word)\n",
    "            tf_idf_scores = [doc[index] for doc in denselist]\n",
    "            similar_words_tf_idf[word] = tf_idf_scores\n",
    "    return similar_words_tf_idf\n",
    "\n",
    "# 예제: '코로나'와 유사한 단어 찾기\n",
    "input_word = '코로나'\n",
    "similar_words_tf_idf = find_similar_words(input_word)\n",
    "\n",
    "# 유사 단어 및 TF-IDF 값 출력\n",
    "for word, scores in similar_words_tf_idf.items():\n",
    "    print(f\"단어: {word}\")\n",
    "    print(f\"TF-IDF 점수: {scores}\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    \n",
    "# 종료 시간 측정\n",
    "end_time = time.time()\n",
    "print(f\"총 걸린 시간: {end_time - start_time} 초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e4412a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
